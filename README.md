## 快速启动指南

## 一、初始化准备

### 1. 按照requirements.txt安装好依赖库

### 2. 配置英雄数据
- 确保`heroes.json`文件中的英雄名称与图片路径映射正确
- `pictures/`目录下需要存在对应的英雄图像文件

## 二、特征匹配功能验证
- 运行`feature_matcher.py`程序（测试的是测试图片.png）

## 三、拿牌功能验证

### 1. 加载模型与特征库
- 运行`交互界面.py`主程序
- 点击界面中的**加载模型**按钮
- 程序将自动完成以下操作：
  - 初始化ResNet-18特征提取器
  - 构建英雄图像特征库
  - 
### 1. 设置递牌区域
1. 点击界面中的**选择递牌区域**（可以选择验证图片.png测试，选择阵容T1验证）
   框选区域示范（选择的区域越规范，检测效果越好）：
   ![image](https://github.com/user-attachments/assets/f9b554b8-d76e-4153-81fa-02dbbcc5dbaa)

3. 按照提示使用鼠标在游戏界面中框选"选秀递牌区"
4. 按**空格键**确认选择
5. 框选的区域坐标将自动保存到`config.py`配置文件中


### 2. 选择拿牌模式

#### 已有阵容模式
- 在界面左侧的"已有阵容"列表中
- 选择预先准备好的阵容文件（存放在`阵容/`目录下）

#### 指定英雄模式
1. 切换到"指定英雄"标签页
2. 按照英雄费用分类浏览可选英雄
3. 勾选需要自动拿取的目标英雄

### 3. 开始自动拿牌
- 点击界面中的**自动拿牌**按钮
- 或直接按键盘**N键**快捷启动

程序将执行以下操作：
1. 截取游戏画面中的递牌区域
2. 将截图分割为单个英雄图像
3. 调用`FeatureMatcher`进行英雄识别匹配
4. 输出识别结果到日志界面
5. 自动点击选取目标英雄
6. 实时显示操作日志在程序界面中

## 三、常见问题
① 运行交互界面闪退？
建一个新项目，把所有文件copy过去（具体原因我也不太清楚）
②其他问题暂时还没有遇到，发现其他问题可在讨论区留言







# RAG 问答系统项目文档

## 项目概述
这是一个基于检索增强生成（RAG）的问答系统，能够根据用户的问题从文档库中检索相关信息并生成准确回答。系统结合了 BM25 词袋模型和语义向量检索的混合检索策略，并通过重排序模型优化检索结果，最后利用大语言模型生成自然语言回答。

## 目录结构说明

### 主要文件夹
- `cache/`：缓存处理后的文档和向量索引，避免重复计算
- `documents/`：存放待检索的文档数据，支持 txt、pdf、docx 格式
- `html/`：前端界面文件，包含用户交互页面
- `model/`：存放预训练模型文件，包括嵌入模型和重排序模型

### 主要文件

#### 核心功能文件
- `app.py`：Flask 应用入口，定义 API 接口和 RAG 系统的整体流程
- `document_loader.py`：文档加载和分割模块，处理不同格式的文档并分割成片段
- `retriever.py`：检索模块，实现混合检索策略（BM25 + 语义向量）
- `reranker.py`：重排序模块，对检索结果进行精排序
- `llm_qa.py`：大语言模型问答模块，生成最终回答
- `cache_manager.py`：缓存管理模块，负责数据缓存和更新

#### 配置和工具文件
- `config.py`：系统配置文件，包含路径、模型参数等配置
- `main.py`：命令行测试入口，用于本地测试系统功能
- `requirements.txt`：依赖库列表，包含项目所需的所有 Python 包
- `readme.md`：项目说明文档，包含部署和使用指南

## 各文件详细说明

### `app.py`
Flask 应用的主文件，实现了 API 接口和 RAG 系统的初始化：
- 定义了`RAGSystem`类，整合文档加载、检索、重排序和 LLM 问答功能
- 提供`/api/search`接口，接收用户问题并返回回答和支持文档
- 集成 CORS 支持，允许跨域请求

### `cache_manager.py`
缓存管理模块，主要功能：
- 提供缓存读写功能，使用 pickle 序列化数据
- 基于文件哈希值生成缓存键，确保文档更新时缓存失效
- 管理文档缓存和向量索引缓存，提高系统性能

### `config.py`
系统配置中心，包含：
- 路径配置：文档目录、缓存目录等
- 处理参数：文档分块大小、重叠量等
- 检索参数：检索数量、重排序数量等
- 模型配置：嵌入模型、重排序模型、LLM 模型等
- API 配置：API 密钥、接口地址等

### `document_loader.py`
文档处理模块，功能包括：
- 加载不同格式的文档（txt、pdf、docx）
- 使用 `RecursiveCharacterTextSplitter` 分割文档为固定大小的片段
- 支持缓存文档片段，避免重复处理
- 处理中文编码问题，确保文档正确加载

### `llm_qa.py`
大语言模型问答模块：
- 初始化 `ChatOpenAI` 模型，支持 DeepSeek 等 LLM
- 定义提示词模板，将检索到的上下文和问题整合为 LLM 输入
- 处理 LLM 响应，生成最终回答
- 支持流式响应处理和错误处理

### `main.py`
命令行测试入口：
- 演示完整的问答流程
- 用于本地测试系统功能
- 输出问题、答案和支持文档的详细信息

### `reranker.py`
重排序模块：
- 使用 BGE 重排序模型对检索结果进行精排序
- 构造 "query: 问题 passage: 文档内容" 的输入格式
- 计算文档与查询的相关性分数
- 返回排序后的结果

### `retriever.py`
检索模块，实现混合检索策略：
- 结合 BM25 词袋模型和语义向量检索
- 使用 `SentenceTransformer` 生成文档嵌入向量
- 使用 `FAISS` 构建向量索引，加速检索过程
- 实现混合评分机制，结合 BM25 和向量相似度分数
